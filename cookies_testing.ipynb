{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cookies & Code - Testing: What, Why, and How!\n",
    "\n",
    "## Learning Intentions\n",
    "\n",
    "- Explain when and why a piece of code needs tests.\n",
    "- Identify key features of tests\n",
    "-  Structure tests using the Arrange-Act-Assert framework.\n",
    "-  Write and run simple tests using pytest \\& ipytest.\n",
    "-  Outline how writing testable code differs from writing code.\n",
    "- Be equipped to start writing your own tests **today**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# What is testing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## What is pytest?\n",
    "There are many packages that can be used to help test Python code.\n",
    "`pytest` is known for its simple language and concise syntax, particularly compared to `unittest` which is part of the Python Standard Library.\n",
    "\n",
    "You need to import `ipytest` to directly run pytest-style tests in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import at beginning of notebook\n",
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "You'll also notice commands beginning with `%%ipytest -qq` in cells containing tests.\n",
    "We'll investigate their role soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## What is a test?\n",
    "A test is a *function* that has an *assert statement*.\n",
    "\n",
    "`pytest`, or `ipytest` runs the test functions. \n",
    "\n",
    "If its assert statements are:\n",
    "- **true** — the test will **pass**!\n",
    "- **false** or an **error** occurs — the test will **fail**.\n",
    "\n",
    "Tests come in a few different flavours - we will deal with **unit tests** today. \n",
    "\n",
    "A unit test tests a small, isolated, piece of code (a unit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Example Set 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Try running (shift + enter) the following cells of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.40s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_example():\n",
    "    assert [1, 2, 3] == [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________________ test_will_fail __________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_will_fail\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3403248648.py\u001b[0m:4: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_will_fail\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.08s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "# What happens if you run the cell without the line above?\n",
    "\n",
    "def test_will_fail():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def this_test_will_not_run():\n",
    "    # Pytest tests are required to begin with the test_ prefix.\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "***Optional:** Experiment by replacing `%%ipytest` with:*\n",
    "- `%%ipytest -vv`\n",
    "- `%%ipytest -qq`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Example Set 2 - Structuring Tests\n",
    "Let's look at a slightly more interesting use case. We have a function \"example_func\" and we want to write some unit tests for it. \n",
    "\n",
    "We will write tests using the Arrange-Act-Assert Framework:\n",
    "\n",
    "- **Arrange:** Create inputs to the function or class you are testing.\n",
    "- **Act:** Call the function or class you are testing.\n",
    "- **Assert:** Assert that you get the output you expected.\n",
    "\n",
    "Look at how the tests below are structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_func(x: int, y: int) -> int:\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Try running the tests. Some should fail! Can you fix them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                          [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________ test_example_func_failing_test __________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_example_func_failing_test\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## This test fails! Can you fix it?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## NB: Requires changing 1 line.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Arrange\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = \u001b[94m20\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        y = \u001b[94m15\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Act\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        output = example_func(x, y)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m output == \u001b[94m20\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 35 == 20\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/383465038.py\u001b[0m:24: AssertionError\n",
      "\u001b[31m\u001b[1m________________________________ test_example_func_fails_with_none _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_example_func_fails_with_none\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## This test fails! What is the problem?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## NB: Requires changing 1 line.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Arrange\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        y = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Act & Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m pytest.raises(\u001b[96mValueError\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">           output = example_func(x, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/383465038.py\u001b[0m:36: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = None, y = 2\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mexample_func\u001b[39;49;00m(x: \u001b[96mint\u001b[39;49;00m, y: \u001b[96mint\u001b[39;49;00m) -> \u001b[96mint\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m x + y\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/1485454122.py\u001b[0m:2: TypeError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_example_func_failing_test\u001b[0m - assert 35 == 20\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_example_func_fails_with_none\u001b[0m - TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n",
      "\u001b[31m\u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_example_func():\n",
    "    ## Arrange\n",
    "    x = 10\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x,  y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 25\n",
    "\n",
    "def test_example_func_failing_test():\n",
    "    ## This test fails! Can you fix it?\n",
    "    ## NB: Requires changing 1 line.\n",
    "\n",
    "    ## Arrange\n",
    "    x = 20\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x, y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 20\n",
    "\n",
    "def test_example_func_fails_with_none():\n",
    "    ## This test fails! What is the problem?\n",
    "    ## NB: Requires changing 1 line.\n",
    "    \n",
    "    ## Arrange\n",
    "    x = None\n",
    "    y = 2\n",
    "\n",
    "    ## Act & Assert\n",
    "    with pytest.raises(ValueError):\n",
    "        output = example_func(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Why do we test?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "\n",
    "- Writing automated unit tests allows us to change code and ensure we do not break existing functionality.\n",
    "- Unit tests are a contract for the intent of the code.\n",
    "\n",
    "\n",
    "## Benefits of testing\n",
    "\n",
    "- Less bugs! A test suite evolves as you fix bugs so they NEVER occur again.\n",
    "- Documents the code.\n",
    "- Forces you to write more modular code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Does this code need tests?\n",
    "\n",
    "I have a piece of code that runs on a server every day at 9am.\n",
    "\t\n",
    "It's run for 15 years and has not been altered since 1992.\n",
    "\t\n",
    "Should I go and write tests for this function?\n",
    "\t\n",
    "What about a simple 5 line script that calls an API & sends an email?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## What code should I test?\n",
    "\n",
    "Generally you should test code that meets one or more of the following conditions:\n",
    "- Used in multiple places,\n",
    "- Frequently changing or under active development,\n",
    "- Important to be correct, or\n",
    "- Complex, with lots of edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The tests are coupled to the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# How to Write Testable Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Testable code should be:\n",
    "- Modular,\n",
    "- Deterministic,\n",
    "- De-coupled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Example 3 - Refactoring\n",
    "\n",
    "I have some code below that reads in some data from a file, and constructs some Star objects with some characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List\n",
    "\n",
    "class Star:\n",
    "    def __init__(self, name: str, distance: float, luminosity: float):\n",
    "        self.name = name\n",
    "        self.distance = distance\n",
    "        self.luminosity = luminosity\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file of star data and returns a list of Star objects.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the CSV file.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            name = row['Name']\n",
    "            distance = float(row['Distance'])\n",
    "            luminosity = float(row['Luminosity'])\n",
    "            star = Star(name, distance, luminosity)\n",
    "            stars.append(star)\n",
    "    \n",
    "    return stars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "What makes testing the above function hard? Think about all the operations that are occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactored version\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def read_star_data(filename: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns the data as a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, str]]: The raw data from the CSV as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def create_star_objects(data: List[Dict[str, str]]) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Converts raw star data into Star objects.\n",
    "    \n",
    "    Args:\n",
    "        data (List[Dict[str, str]]): Raw data containing star information.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the raw data.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    for row in data:\n",
    "        name = row['Name']\n",
    "        distance = float(row['Distance'])\n",
    "        luminosity = float(row['Luminosity'])\n",
    "        star = Star(name, distance, luminosity)\n",
    "        stars.append(star)\n",
    "    return stars\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Processes the astronomy data by reading and creating Star objects.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects.\n",
    "    \"\"\"\n",
    "    raw_data = read_star_data(filename)\n",
    "    return create_star_objects(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m___________________________________ test_process_astronomy_data ____________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_process_astronomy_data\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# This test fails. Can you use the debugger to figure out why?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        stars = process_astronomy_data(\u001b[33m\"\u001b[39;49;00m\u001b[33mfake_data.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(stars) == \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 0 == 2\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 0 = len([])\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/184344751.py\u001b[0m:25: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_process_astronomy_data\u001b[0m - assert 0 == 2\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "from unittest.mock import patch, mock_open\n",
    "\n",
    "sample_data = [\n",
    "    {\"Name\": \"Star A\", \"Distance\": \"10\", \"Luminosity\": \"1000\"},\n",
    "    {\"Name\": \"Star B\", \"Distance\": \"20\", \"Luminosity\": \"2000\"}\n",
    "]\n",
    "\n",
    "@pytest.mark.parametrize(\"data,expected_stars\", [\n",
    "    (sample_data, [\n",
    "        Star(\"Star A\", 10.0, 1000.0),\n",
    "        Star(\"Star B\", 20.0, 2000.0)\n",
    "    ])\n",
    "])\n",
    "def test_create_star_objects(data, expected_stars):\n",
    "    stars = create_star_objects(data)\n",
    "    for star, expected_star in zip(stars, expected_stars):\n",
    "        assert star.name == expected_star.name\n",
    "        assert star.distance == expected_star.distance\n",
    "        assert star.luminosity == expected_star.luminosity\n",
    "\n",
    "# Using a dummy file to test data ingestion. Look at fake_data.csv.\n",
    "def test_process_astronomy_data():\n",
    "    # This test fails. Can you use the debugger to figure out why?\n",
    "    stars = process_astronomy_data(\"fake_data.csv\")\n",
    "    assert len(stars) == 2\n",
    "    assert stars[0].name == \"Star A\"\n",
    "    assert stars[1].name == \"Star B\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Fancier things - if you have time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Run test .py scripts using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Run a single file of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.26s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_example_functions.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Run all tests in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: /Users/jsmallwood/Documents/projects/cookies-testing\n",
      "plugins: hypothesis-6.130.9, anyio-4.9.0\n",
      "collected 15 items                                                             \u001b[0m\n",
      "\n",
      "test_example_functions.py \u001b[32m.\u001b[0m\u001b[32m                                              [  6%]\u001b[0m\n",
      "test_using_parametrize.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Run tests with detailed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0 -- /Users/jsmallwood/Documents/projects/cookies-testing/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/Users/jsmallwood/Documents/projects/cookies-testing/.hypothesis/examples'))\n",
      "rootdir: /Users/jsmallwood/Documents/projects/cookies-testing\n",
      "plugins: hypothesis-6.130.9, anyio-4.9.0\n",
      "collected 15 items                                                             \u001b[0m\n",
      "\n",
      "test_example_functions.py::test_additive_inverse \u001b[32mPASSED\u001b[0m\u001b[32m                  [  6%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[-4--1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 13%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 20%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[0-3] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 26%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[9-12] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 33%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[-4--1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 40%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 46%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[0-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 53%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[9-12] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 60%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-6] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 66%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-4] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 73%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 80%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[0] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 86%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[3] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 93%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[9] \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Using pytest.mark.parameterize\n",
    "\n",
    "Allows the same test function to run for many input / output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_number(x: int) -> int:\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"input_num,expected_output\", [\n",
    "    (2, 4), (-2, 4), (8, 64)\n",
    "])\n",
    "def test_square_number(input_num, expected_output):\n",
    "    ## Arrange\n",
    "    ## Nothing to do here\n",
    "\n",
    "    ## Act\n",
    "    output = square_number(input_num)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Fixtures\n",
    "\n",
    "Allow re-use of setup objects that you use again and again - for instance reading an input file. Here's an example from pycodif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for an example - this won't run.\n",
    "## The \"example_frame\" code is executed before each test\n",
    "## and the output passed in the \"example_frame\" argument.\n",
    "class TestCODIFFrame:\n",
    "\n",
    "    @pytest.fixture()\n",
    "    def example_frame(self):\n",
    "        with open(\"tests/test_files/test_codif.codif\", \"rb\") as f:\n",
    "            codif = CODIFFrame(f)\n",
    "        return codif\n",
    "\n",
    "    def test_data_parsing(self, example_frame):\n",
    "        assert hasattr(example_frame, \"header\")\n",
    "        assert hasattr(example_frame, \"data_array\")\n",
    "        assert hasattr(example_frame, \"sample_timestamps\")\n",
    "\n",
    "    def test_data_values(self, example_frame):\n",
    "        assert isinstance(example_frame.data_array, np.ndarray)\n",
    "        assert example_frame.data_array.dtype == np.dtype(\"complex64\")\n",
    "        assert example_frame.data_array[0, 0] == -23 + 45j\n",
    "        assert example_frame.data_array[0, -1] == 113 - 89j\n",
    "        assert example_frame.data_array[-1, 0] == 45j\n",
    "        assert example_frame.data_array[-1, -1] == -43 + 58j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "This is a package that generates test cases for us based on properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________________ test_integers ___________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@given\u001b[39;49;00m(st.integers(\u001b[94m0\u001b[39;49;00m, \u001b[94m200\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      ">   \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_integers\u001b[39;49;00m(n):\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/2354737801.py\u001b[0m:6: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "n = 50\n",
      "\n",
      "    \u001b[0m\u001b[37m@given\u001b[39;49;00m(st.integers(\u001b[94m0\u001b[39;49;00m, \u001b[94m200\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_integers\u001b[39;49;00m(n):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m n < \u001b[94m50\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 50 < 50\u001b[0m\n",
      "\u001b[1m\u001b[31mE       Falsifying example: test_integers(\u001b[0m\n",
      "\u001b[1m\u001b[31mE           n=50,\u001b[0m\n",
      "\u001b[1m\u001b[31mE       )\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/2354737801.py\u001b[0m:7: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_integers\u001b[0m - assert 50 < 50\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 1.39s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "# Taken from hypothesis quickstart guide:\n",
    "# https://hypothesis.readthedocs.io/en/latest/quickstart.html\n",
    "from hypothesis import given, strategies as st\n",
    "\n",
    "@given(st.integers(0, 200))\n",
    "def test_integers(n):\n",
    "    assert n < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m______________________________________ test_inverses_integers ______________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@given\u001b[39;49;00m(s=st.integers())\u001b[90m\u001b[39;49;00m\n",
      ">   \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_inverses_integers\u001b[39;49;00m(s):\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\u001b[0m:15: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "s = -1\n",
      "\n",
      "    \u001b[0m\u001b[37m@given\u001b[39;49;00m(s=st.integers())\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_inverses_integers\u001b[39;49;00m(s):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m np.isclose(s, square(square_root(s)))\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m np.isclose(s, square_root(square(s)))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert np.False_\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where np.False_ = <function isclose at 0x1054c33b0>(-1, 1.0)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <function isclose at 0x1054c33b0> = np.isclose\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    and   1.0 = square_root(1)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where 1 = square(-1)\u001b[0m\n",
      "\u001b[1m\u001b[31mE       Falsifying example: test_inverses_integers(\u001b[0m\n",
      "\u001b[1m\u001b[31mE           s=-1,\u001b[0m\n",
      "\u001b[1m\u001b[31mE       )\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\u001b[0m:17: AssertionError\n",
      "\u001b[31m\u001b[1m_______________________________________ test_inverses_floats _______________________________________\u001b[0m\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/runner.py\", line 341, in from_call\n",
      "  |     result: TResult | None = func()\n",
      "  |                              ~~~~^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/runner.py\", line 242, in <lambda>\n",
      "  |     lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n",
      "  |             ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_hooks.py\", line 513, in __call__\n",
      "  |     return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n",
      "  |            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n",
      "  |     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n",
      "  |            ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 182, in _multicall\n",
      "  |     return outcome.get_result()\n",
      "  |            ~~~~~~~~~~~~~~~~~~^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_result.py\", line 100, in get_result\n",
      "  |     raise exc.with_traceback(exc.__traceback__)\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\n",
      "  |     teardown.throw(outcome._exception)\n",
      "  |     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/threadexception.py\", line 92, in pytest_runtest_call\n",
      "  |     yield from thread_exception_runtest_hook()\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/threadexception.py\", line 68, in thread_exception_runtest_hook\n",
      "  |     yield\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\n",
      "  |     teardown.throw(outcome._exception)\n",
      "  |     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/unraisableexception.py\", line 95, in pytest_runtest_call\n",
      "  |     yield from unraisable_exception_runtest_hook()\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/unraisableexception.py\", line 70, in unraisable_exception_runtest_hook\n",
      "  |     yield\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\n",
      "  |     teardown.throw(outcome._exception)\n",
      "  |     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/logging.py\", line 846, in pytest_runtest_call\n",
      "  |     yield from self._runtest_for(item, \"call\")\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/logging.py\", line 829, in _runtest_for\n",
      "  |     yield\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\n",
      "  |     teardown.throw(outcome._exception)\n",
      "  |     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/capture.py\", line 898, in pytest_runtest_call\n",
      "  |     return (yield)\n",
      "  |             ^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\n",
      "  |     teardown.throw(outcome._exception)\n",
      "  |     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/skipping.py\", line 257, in pytest_runtest_call\n",
      "  |     return (yield)\n",
      "  |             ^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 103, in _multicall\n",
      "  |     res = hook_impl.function(*args)\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/runner.py\", line 174, in pytest_runtest_call\n",
      "  |     item.runtest()\n",
      "  |     ~~~~~~~~~~~~^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/python.py\", line 1627, in runtest\n",
      "  |     self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n",
      "  |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_hooks.py\", line 513, in __call__\n",
      "  |     return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n",
      "  |            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n",
      "  |     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n",
      "  |            ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 139, in _multicall\n",
      "  |     raise exception.with_traceback(exception.__traceback__)\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/pluggy/_callers.py\", line 103, in _multicall\n",
      "  |     res = hook_impl.function(*args)\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/_pytest/python.py\", line 159, in pytest_pyfunc_call\n",
      "  |     result = testfunction(**testargs)\n",
      "  |   File \"/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\", line 20, in test_inverses_floats\n",
      "  |     def test_inverses_floats(s):\n",
      "  |                    ^^^\n",
      "  |   File \"/Users/jsmallwood/Documents/projects/cookies-testing/.venv/lib/python3.13/site-packages/hypothesis/core.py\", line 1837, in wrapped_test\n",
      "  |     raise the_error_hypothesis_found\n",
      "  | ExceptionGroup: Hypothesis found 3 distinct failures. (3 sub-exceptions)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\", line 22, in test_inverses_floats\n",
      "    |     assert np.isclose(s, square_root(square(s)))\n",
      "    | AssertionError: assert np.False_\n",
      "    |  +  where np.False_ = <function isclose at 0x1054c33b0>(-1.0, 1.0)\n",
      "    |  +    where <function isclose at 0x1054c33b0> = np.isclose\n",
      "    |  +    and   1.0 = square_root(1.0)\n",
      "    |  +      where 1.0 = square(-1.0)\n",
      "    | Falsifying example: test_inverses_floats(\n",
      "    |     s=-1.0,\n",
      "    | )\n",
      "    +---------------- 2 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\", line 21, in test_inverses_floats\n",
      "    |     assert np.isclose(s, square(square_root(s)))\n",
      "    | AssertionError: assert np.False_\n",
      "    |  +  where np.False_ = <function isclose at 0x1054c33b0>(nan, nan)\n",
      "    |  +    where <function isclose at 0x1054c33b0> = np.isclose\n",
      "    |  +    and   nan = square(nan)\n",
      "    |  +      where nan = square_root(nan)\n",
      "    | Falsifying example: test_inverses_floats(\n",
      "    |     s=nan,\n",
      "    | )\n",
      "    +---------------- 3 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\", line 22, in test_inverses_floats\n",
      "    |     assert np.isclose(s, square_root(square(s)))\n",
      "    |                                      ~~~~~~^^^\n",
      "    |   File \"/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_8145/3881189325.py\", line 9, in square\n",
      "    |     return x ** 2\n",
      "    |            ~~^^~~\n",
      "    | OverflowError: (34, 'Result too large')\n",
      "    | Falsifying example: test_inverses_floats(\n",
      "    |     s=1.3407807929942597e+154,\n",
      "    | )\n",
      "    +------------------------------------\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_inverses_integers\u001b[0m - assert np.False_\n",
      "\u001b[31mFAILED\u001b[0m t_4d9120d0c8834c95b5cc1d988dccc58d.py::\u001b[1mtest_inverses_floats\u001b[0m - ExceptionGroup: Hypothesis found 3 distinct failures. (3 sub-exceptions)\n",
      "\u001b[31m\u001b[31m\u001b[1m2 failed\u001b[0m\u001b[31m in 0.33s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "## Some of these fail. Is that expected?\n",
    "## Can you fix them? \n",
    "## NB: Look at the section on filtering here: https://hypothesis.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "def square(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 2\n",
    "\n",
    "def square_root(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 0.5\n",
    "\n",
    "@given(s=st.integers())\n",
    "def test_inverses_integers(s):\n",
    "    assert np.isclose(s, square(square_root(s)))\n",
    "    assert np.isclose(s, square_root(square(s)))\n",
    "\n",
    "@given(s=st.floats())\n",
    "def test_inverses_floats(s):\n",
    "    assert np.isclose(s, square(square_root(s)))\n",
    "    assert np.isclose(s, square_root(square(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c10f0-09c0-4282-a6b8-d8336e9a6b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
