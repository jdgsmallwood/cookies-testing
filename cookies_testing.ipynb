{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cookies & Code - Testing: What, Why, and How!\n",
    "\n",
    "## Learning Intentions\n",
    "\n",
    "- Explain when and why a piece of code needs tests.\n",
    "- Identify key features of tests\n",
    "-  Structure tests using the Arrange-Act-Assert framework.\n",
    "-  Write and run simple tests using pytest \\& ipytest.\n",
    "-  Outline how writing testable code differs from writing code.\n",
    "- Be equipped to start writing your own tests **today**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# What is testing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## What is pytest?\n",
    "There are many packages that can be used to help test Python code.\n",
    "`pytest` is known for its simple language and concise syntax, particularly compared to `unittest` which is part of the Python Standard Library.\n",
    "\n",
    "You need to import `ipytest` to directly run pytest-style tests in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import at beginning of notebook\n",
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "You'll also notice commands beginning with `%%ipytest -qq` in cells containing tests.\n",
    "We'll investigate their role soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## What is a test?\n",
    "A test is a *function* that has an *assert statement*.\n",
    "\n",
    "`pytest`, or `ipytest` runs the test functions. \n",
    "\n",
    "If its assert statements are:\n",
    "- **true** — the test will **pass**!\n",
    "- **false** or an **error** occurs — the test will **fail**.\n",
    "\n",
    "Tests come in a few different flavours - we will deal with **unit tests** today. \n",
    "\n",
    "A unit test tests a small, isolated, piece of code (a unit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Example Set 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Try running (shift + enter) the following cells of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_example():\n",
    "    assert [1, 2, 3] == [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "# What happens if you run the cell without the line above?\n",
    "\n",
    "def test_will_fail():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def this_test_will_not_run():\n",
    "    # Pytest tests are required to begin with the test_ prefix.\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "***Optional:** Experiment by replacing `%%ipytest` with:*\n",
    "- `%%ipytest -vv`\n",
    "- `%%ipytest -qq`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Example Set 2 - Structuring Tests\n",
    "Let's look at a slightly more interesting use case. We have a function \"example_func\" and we want to write some unit tests for it. \n",
    "\n",
    "We will write tests using the Arrange-Act-Assert Framework:\n",
    "\n",
    "- **Arrange:** Create inputs to the function or class you are testing.\n",
    "- **Act:** Call the function or class you are testing.\n",
    "- **Assert:** Assert that you get the output you expected.\n",
    "\n",
    "Look at how the tests below are structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_func(x: int, y: int) -> int:\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Try running the tests. Some should fail! Can you fix them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_example_func():\n",
    "    ## Arrange\n",
    "    x = 10\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x,  y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 25\n",
    "\n",
    "def test_example_func_failing_test():\n",
    "    ## This test fails! Can you fix it?\n",
    "    ## NB: Requires changing 1 line.\n",
    "\n",
    "    ## Arrange\n",
    "    x = 20\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x, y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 20\n",
    "\n",
    "def test_example_func_fails_with_none():\n",
    "    ## This test fails! What is the problem?\n",
    "    ## NB: Requires changing 1 line.\n",
    "    \n",
    "    ## Arrange\n",
    "    x = None\n",
    "    y = 2\n",
    "\n",
    "    ## Act & Assert\n",
    "    with pytest.raises(ValueError):\n",
    "        output = example_func(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Why do we test?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "\n",
    "- Writing automated unit tests allows us to change code and ensure we do not break existing functionality.\n",
    "- Unit tests are a contract for the intent of the code.\n",
    "\n",
    "\n",
    "## Benefits of testing\n",
    "\n",
    "- Less bugs! A test suite evolves as you fix bugs so they NEVER occur again.\n",
    "- Documents the code.\n",
    "- Forces you to write more modular code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Does this code need tests?\n",
    "\n",
    "I have a piece of code that runs on a server every day at 9am.\n",
    "\t\n",
    "It's run for 15 years and has not been altered since 1992.\n",
    "\t\n",
    "Should I go and write tests for this function?\n",
    "\t\n",
    "What about a simple 5 line script that calls an API & sends an email?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## What code should I test?\n",
    "\n",
    "Generally you should test code that meets one or more of the following conditions:\n",
    "- Used in multiple places,\n",
    "- Frequently changing or under active development,\n",
    "- Important to be correct, or\n",
    "- Complex, with lots of edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The tests are coupled to the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# How to Write Testable Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Testable code should be:\n",
    "- Modular,\n",
    "- Deterministic,\n",
    "- De-coupled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Example 3 - Refactoring\n",
    "\n",
    "I have some code below that reads in some data from a file, and constructs some Star objects with some characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List\n",
    "\n",
    "class Star:\n",
    "    def __init__(self, name: str, distance: float, luminosity: float):\n",
    "        self.name = name\n",
    "        self.distance = distance\n",
    "        self.luminosity = luminosity\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file of star data and returns a list of Star objects.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the CSV file.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            name = row['Name']\n",
    "            distance = float(row['Distance'])\n",
    "            luminosity = float(row['Luminosity'])\n",
    "            star = Star(name, distance, luminosity)\n",
    "            stars.append(star)\n",
    "    \n",
    "    return stars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "What makes testing the above function hard? Think about all the operations that are occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactored version\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def read_star_data(filename: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns the data as a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, str]]: The raw data from the CSV as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def create_star_objects(data: List[Dict[str, str]]) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Converts raw star data into Star objects.\n",
    "    \n",
    "    Args:\n",
    "        data (List[Dict[str, str]]): Raw data containing star information.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the raw data.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    for row in data:\n",
    "        name = row['Name']\n",
    "        distance = float(row['Distance'])\n",
    "        luminosity = float(row['Luminosity'])\n",
    "        star = Star(name, distance, luminosity)\n",
    "        stars.append(star)\n",
    "    return stars\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Processes the astronomy data by reading and creating Star objects.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects.\n",
    "    \"\"\"\n",
    "    raw_data = read_star_data(filename)\n",
    "    return create_star_objects(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -qq\n",
    "from unittest.mock import patch, mock_open\n",
    "\n",
    "sample_data = [\n",
    "    {\"Name\": \"Star A\", \"Distance\": \"10\", \"Luminosity\": \"1000\"},\n",
    "    {\"Name\": \"Star B\", \"Distance\": \"20\", \"Luminosity\": \"2000\"}\n",
    "]\n",
    "\n",
    "@pytest.mark.parametrize(\"data,expected_stars\", [\n",
    "    (sample_data, [\n",
    "        Star(\"Star A\", 10.0, 1000.0),\n",
    "        Star(\"Star B\", 20.0, 2000.0)\n",
    "    ])\n",
    "])\n",
    "def test_create_star_objects(data, expected_stars):\n",
    "    stars = create_star_objects(data)\n",
    "    for star, expected_star in zip(stars, expected_stars):\n",
    "        assert star.name == expected_star.name\n",
    "        assert star.distance == expected_star.distance\n",
    "        assert star.luminosity == expected_star.luminosity\n",
    "\n",
    "# Using a dummy file to test data ingestion. Look at fake_data.csv.\n",
    "def test_process_astronomy_data():\n",
    "    # This test fails. Can you use the debugger to figure out why?\n",
    "    stars = process_astronomy_data(\"fake_data.csv\")\n",
    "    assert len(stars) == 2\n",
    "    assert stars[0].name == \"Star A\"\n",
    "    assert stars[1].name == \"Star B\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Fancier things - if you have time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Run test .py scripts using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Run a single file of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_example_functions.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Run all tests in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Run tests with detailed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Using pytest.mark.parameterize\n",
    "\n",
    "Allows the same test function to run for many input / output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_number(x: int) -> int:\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest -qq\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"input_num,expected_output\", [\n",
    "    (2, 4), (-2, 4), (8, 64)\n",
    "])\n",
    "def test_square_number(input_num, expected_output):\n",
    "    ## Arrange\n",
    "    ## Nothing to do here\n",
    "\n",
    "    ## Act\n",
    "    output = square_number(input_num)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Fixtures\n",
    "\n",
    "Allow re-use of setup objects that you use again and again - for instance reading an input file. Here's an example from pycodif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for an example - this won't run.\n",
    "## The \"example_frame\" code is executed before each test\n",
    "## and the output passed in the \"example_frame\" argument.\n",
    "class TestCODIFFrame:\n",
    "\n",
    "    @pytest.fixture()\n",
    "    def example_frame(self):\n",
    "        with open(\"tests/test_files/test_codif.codif\", \"rb\") as f:\n",
    "            codif = CODIFFrame(f)\n",
    "        return codif\n",
    "\n",
    "    def test_data_parsing(self, example_frame):\n",
    "        assert hasattr(example_frame, \"header\")\n",
    "        assert hasattr(example_frame, \"data_array\")\n",
    "        assert hasattr(example_frame, \"sample_timestamps\")\n",
    "\n",
    "    def test_data_values(self, example_frame):\n",
    "        assert isinstance(example_frame.data_array, np.ndarray)\n",
    "        assert example_frame.data_array.dtype == np.dtype(\"complex64\")\n",
    "        assert example_frame.data_array[0, 0] == -23 + 45j\n",
    "        assert example_frame.data_array[0, -1] == 113 - 89j\n",
    "        assert example_frame.data_array[-1, 0] == 45j\n",
    "        assert example_frame.data_array[-1, -1] == -43 + 58j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "This is a package that generates test cases for us based on properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "# Taken from hypothesis quickstart guide:\n",
    "# https://hypothesis.readthedocs.io/en/latest/quickstart.html\n",
    "from hypothesis import given, strategies as st\n",
    "\n",
    "@given(st.integers(0, 200))\n",
    "def test_integers(n):\n",
    "    assert n < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "## Some of these fail. Is that expected?\n",
    "## Can you fix them? \n",
    "## NB: Look at the section on filtering here: https://hypothesis.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "def square(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 2\n",
    "\n",
    "def square_root(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 0.5\n",
    "\n",
    "@given(s=st.integers())\n",
    "def test_inverses_integers(s):\n",
    "    assert np.isclose(s, square(square_root(s)))\n",
    "    assert np.isclose(s, square_root(square(s)))\n",
    "\n",
    "@given(s=st.floats())\n",
    "def test_inverses_floats(s):\n",
    "    assert np.isclose(s, square(square_root(s)))\n",
    "    assert np.isclose(s, square_root(square(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
