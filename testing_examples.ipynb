{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b373adca-7acd-4f19-8302-e345672a50fd",
   "metadata": {},
   "source": [
    "# Cookies & Code - Testing: What, Why, and How!\n",
    "\n",
    "## Learning Intentions\n",
    "\n",
    "- Explain when and why a piece of code needs tests.\n",
    "- Identify key features of tests\n",
    "-  Structure tests using the Arrange-Act-Assert framework.\n",
    "-  Write and run simple tests using pytest \\& ipytest.\n",
    "-  Outline how writing testable code differs from writing code.\n",
    "- Be equipped to start writing your own tests **today**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7c463-789b-40d3-be2b-0f3d58e6ee3b",
   "metadata": {},
   "source": [
    "## What is pytest?\n",
    "There are many packages that can be used to help test Python code.\n",
    "Pytest is known for its simple language and concise syntax, particularly compared to unittest which is part of the Python Standard Library.\n",
    "\n",
    "You need to import `ipytest` to directly run pytest-style tests in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a31881d-9a05-4cff-b516-92584f4bc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import at beginning of notebook\n",
    "import ipytest\n",
    "import pytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0407c25-5845-4a35-b64a-60561fdc1362",
   "metadata": {},
   "source": [
    "You'll also notice commands beginning with `%%ipytest -qq` in cells containing tests.\n",
    "We'll investigate their role soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c075bd8-bab0-4402-a196-24f741bc7aab",
   "metadata": {},
   "source": [
    "# What is a test?\n",
    "A test is a *function* that has an *assert statement*.\n",
    "\n",
    "Pytest, or ipytest runs the test functions. \n",
    "\n",
    "If its assert statements are:\n",
    "- **true** — the test will **pass**!\n",
    "- **false** or an **error** occurs — the test will **fail**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7123727-34c2-4d5e-a29f-e12538f91ff0",
   "metadata": {},
   "source": [
    "## Example Set 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771df029-8cbd-4ca2-ac40-584648ec096b",
   "metadata": {},
   "source": [
    "Try running (shift + enter) the following cells of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d0b62ad-d347-403c-8f3c-1462dbdcca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_example():\n",
    "    assert [1, 2, 3] == [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "657d19ed-7d60-4d82-9aac-8998ed1fe9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________________ test_will_fail __________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_will_fail\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_57154/3403248648.py\u001b[0m:4: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_422d6850be72477e9076ee8297af0f6b.py::\u001b[1mtest_will_fail\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "# What happens if you run the cell without the line above?\n",
    "\n",
    "def test_will_fail():\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84eff09f-aee4-400d-87ed-db11f6e30cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def this_test_will_not_run():\n",
    "    # Pytest tests are required to begin with the test_ prefix.\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb36ab8-c04b-4e14-a6b0-1e17e84db95d",
   "metadata": {},
   "source": [
    "***Optional:** Experiment by replacing `%%ipytest` with:*\n",
    "- `%%ipytest -vv`\n",
    "- `%%ipytest -qq`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b508ce-ca8f-4e01-bc1a-c1393ba3736b",
   "metadata": {},
   "source": [
    "## Example Set 2 - Structuring Tests\n",
    "Let's look at a slightly more interesting use case. We have a function \"example_func\" and we want to write some unit tests for it. \n",
    "\n",
    "We will write tests using the Arrange-Act-Assert Framework:\n",
    "\n",
    "- **Arrange:** Create inputs to the function or class you are testing.\n",
    "- **Act:** Call the function or class you are testing.\n",
    "- **Assert:** Assert that you get the output you expected.\n",
    "\n",
    "Look at how the tests below are structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5761f59f-f9b5-4955-b6b3-ac833c4fd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_func(x: int, y: int) -> int:\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9568dcc-5e98-45a1-8675-379f2eac8300",
   "metadata": {},
   "source": [
    "Try running the tests. Some should fail! Can you fix them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1090d310-a721-4614-a60b-d1ce7f4ba6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                          [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________________ test_example_func_failing_test __________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_example_func_failing_test\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## This test fails! Can you fix it?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## NB: Requires changing 1 line.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Arrange\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = \u001b[94m20\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        y = \u001b[94m15\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Act\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        output = example_func(x, y)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m output == \u001b[94m20\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 35 == 20\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_57154/383465038.py\u001b[0m:24: AssertionError\n",
      "\u001b[31m\u001b[1m________________________________ test_example_func_fails_with_none _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_example_func_fails_with_none\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## This test fails! What is the problem?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## NB: Requires changing 1 line.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Arrange\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        x = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        y = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## Act & Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m pytest.raises(\u001b[96mValueError\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">           output = example_func(x, y)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_57154/383465038.py\u001b[0m:36: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = None, y = 2\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mexample_func\u001b[39;49;00m(x: \u001b[96mint\u001b[39;49;00m, y: \u001b[96mint\u001b[39;49;00m) -> \u001b[96mint\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m x + y\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_57154/1485454122.py\u001b[0m:2: TypeError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_422d6850be72477e9076ee8297af0f6b.py::\u001b[1mtest_example_func_failing_test\u001b[0m - assert 35 == 20\n",
      "\u001b[31mFAILED\u001b[0m t_422d6850be72477e9076ee8297af0f6b.py::\u001b[1mtest_example_func_fails_with_none\u001b[0m - TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "\n",
    "def test_example_func():\n",
    "    ## Arrange\n",
    "    x = 10\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x,  y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 25\n",
    "\n",
    "def test_example_func_failing_test():\n",
    "    ## This test fails! Can you fix it?\n",
    "    ## NB: Requires changing 1 line.\n",
    "\n",
    "    ## Arrange\n",
    "    x = 20\n",
    "    y = 15\n",
    "\n",
    "    ## Act\n",
    "    output = example_func(x, y)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == 20\n",
    "\n",
    "def test_example_func_fails_with_none():\n",
    "    ## This test fails! What is the problem?\n",
    "    ## NB: Requires changing 1 line.\n",
    "    \n",
    "    ## Arrange\n",
    "    x = None\n",
    "    y = 2\n",
    "\n",
    "    ## Act & Assert\n",
    "    with pytest.raises(ValueError):\n",
    "        output = example_func(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c084b-f0de-4642-8d65-fa92fdd482ab",
   "metadata": {},
   "source": [
    "## Why do we test?\n",
    "\n",
    "\n",
    "- Writing automated unit tests allows us to change code and ensure we do not break existing functionality.\n",
    "- Unit tests are a contract for the intent of the code.\n",
    "\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Less bugs! A test suite evolves as you fix bugs so they NEVER occur again.\n",
    "- Documents the code.\n",
    "- Forces you to write more modular code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce04d6-903c-47fd-8607-bf931dbbb1ac",
   "metadata": {},
   "source": [
    "### Does this code need tests?\n",
    "\n",
    "I have a piece of code that runs on a server every day at 9am.\n",
    "\t\n",
    "It's run for 15 years and has not been altered since 1992.\n",
    "\t\n",
    "Should I go and write tests for this function?\n",
    "\t\n",
    "What about a simple 5 line script that calls an API & sends an email?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6beefb7-ce0f-4848-895d-1bf433dc2325",
   "metadata": {},
   "source": [
    "### What code should I test?\n",
    "\n",
    "Generally you should test code that meets one or more of the following conditions:\n",
    "- Used in multiple places,\n",
    "- Frequently changing or under active development,\n",
    "- Important to be correct, or\n",
    "- Complex, with lots of edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16295295-b996-4ae1-94da-b3e06484d1cc",
   "metadata": {},
   "source": [
    "The tests are coupled to the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfafa29-3293-48b8-9c7f-1c85128374dc",
   "metadata": {},
   "source": [
    "## How to Write Testable Code\n",
    "\n",
    "Testable code should be:\n",
    "- Modular,\n",
    "- Deterministic,\n",
    "- De-coupled.\n",
    "\n",
    "\n",
    "### Example 3 - Refactoring\n",
    "\n",
    "I have some code below that reads in some data from a file, and constructs some Star objects with some characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e5fe242-14a9-4570-a936-b585e827a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List\n",
    "\n",
    "class Star:\n",
    "    def __init__(self, name: str, distance: float, luminosity: float):\n",
    "        self.name = name\n",
    "        self.distance = distance\n",
    "        self.luminosity = luminosity\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file of star data and returns a list of Star objects.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the CSV file.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            name = row['Name']\n",
    "            distance = float(row['Distance'])\n",
    "            luminosity = float(row['Luminosity'])\n",
    "            star = Star(name, distance, luminosity)\n",
    "            stars.append(star)\n",
    "    \n",
    "    return stars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23ce57-4257-4383-99c6-5e5185448c31",
   "metadata": {},
   "source": [
    "What makes testing the above function hard? Think about all the operations that are occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88de72d5-fec1-4246-998b-dd8d6135a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactored version\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def read_star_data(filename: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns the data as a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, str]]: The raw data from the CSV as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return [row for row in reader]\n",
    "\n",
    "def create_star_objects(data: List[Dict[str, str]]) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Converts raw star data into Star objects.\n",
    "    \n",
    "    Args:\n",
    "        data (List[Dict[str, str]]): Raw data containing star information.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects created from the raw data.\n",
    "    \"\"\"\n",
    "    stars = []\n",
    "    for row in data:\n",
    "        name = row['Name']\n",
    "        distance = float(row['Distance'])\n",
    "        luminosity = float(row['Luminosity'])\n",
    "        star = Star(name, distance, luminosity)\n",
    "        stars.append(star)\n",
    "    return stars\n",
    "\n",
    "def process_astronomy_data(filename: str) -> List[Star]:\n",
    "    \"\"\"\n",
    "    Processes the astronomy data by reading and creating Star objects.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the CSV file containing star data.\n",
    "    \n",
    "    Returns:\n",
    "        List[Star]: A list of Star objects.\n",
    "    \"\"\"\n",
    "    raw_data = read_star_data(filename)\n",
    "    return create_star_objects(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eeb2b115-20e7-4b2e-89e5-aca5ba8b54e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                                           [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m___________________________________ test_process_astronomy_data ____________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_process_astronomy_data\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# This test fails. Can you use the debugger to figure out why?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        stars = process_astronomy_data(\u001b[33m\"\u001b[39;49;00m\u001b[33mfake_data.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(stars) == \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 0 == 2\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 0 = len([])\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/vv/d9ncb4ms2x1gl0mmkrvk8m7c0000gp/T/ipykernel_64744/702681110.py\u001b[0m:25: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_6651fbd894764815bb8c2b5f3a5d5116.py::\u001b[1mtest_process_astronomy_data\u001b[0m - assert 0 == 2\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "from unittest.mock import patch, mock_open\n",
    "\n",
    "sample_data = [\n",
    "    {\"Name\": \"Star A\", \"Distance\": \"10\", \"Luminosity\": \"1000\"},\n",
    "    {\"Name\": \"Star B\", \"Distance\": \"20\", \"Luminosity\": \"2000\"}\n",
    "]\n",
    "\n",
    "@pytest.mark.parametrize(\"data,expected_stars\", [\n",
    "    (sample_data, [\n",
    "        Star(\"Star A\", 10.0, 1000.0),\n",
    "        Star(\"Star B\", 20.0, 2000.0)\n",
    "    ])\n",
    "])\n",
    "def test_create_star_objects(data, expected_stars):\n",
    "    stars = create_star_objects(data)\n",
    "    for star, expected_star in zip(stars, expected_stars):\n",
    "        assert star.name == expected_star.name\n",
    "        assert star.distance == expected_star.distance\n",
    "        assert star.luminosity == expected_star.luminosity\n",
    "\n",
    "# Using a dummy file to test data ingestion. Look at fake_data.csv.\n",
    "def test_process_astronomy_data():\n",
    "    # This test fails. Can you use the debugger to figure out why?\n",
    "    stars = process_astronomy_data(\"fake_data.csv\")\n",
    "    assert len(stars) == 2\n",
    "    assert stars[0].name == \"Star A\"\n",
    "    assert stars[1].name == \"Star B\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5bef2-a3ae-414a-9943-722721c9e39c",
   "metadata": {},
   "source": [
    "# Fancier things - if you have time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb82bf6-0789-4b7a-8039-dd93ae5b7539",
   "metadata": {},
   "source": [
    "## Run test .py scripts using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af5dbc-bd71-4e42-a512-30051db5b7bb",
   "metadata": {},
   "source": [
    "#### Run a single file of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c38ddfb-d18e-4277-bf28-79f69d0615f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.00s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_example_functions.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915c41f-929f-4918-984c-58262ed34e56",
   "metadata": {},
   "source": [
    "#### Run all tests in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38046c6b-734e-4a4d-a913-b0d55085ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: /Users/jsmallwood/Documents/projects/cookies-testing\n",
      "plugins: anyio-4.9.0\n",
      "collected 15 items                                                             \u001b[0m\n",
      "\n",
      "test_example_functions.py \u001b[32m.\u001b[0m\u001b[32m                                              [  6%]\u001b[0m\n",
      "test_using_parametrize.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 0.05s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420ffe5-fea0-48c0-85dd-6491fa5d2803",
   "metadata": {},
   "source": [
    "#### Run tests with detailed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59f496ba-dc7d-43d1-bbcc-c1f765d24463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0 -- /Users/jsmallwood/Documents/projects/cookies-testing/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/jsmallwood/Documents/projects/cookies-testing\n",
      "plugins: anyio-4.9.0\n",
      "collected 15 items                                                             \u001b[0m\n",
      "\n",
      "test_example_functions.py::test_additive_inverse \u001b[32mPASSED\u001b[0m\u001b[32m                  [  6%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[-4--1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 13%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 20%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[0-3] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 26%]\u001b[0m\n",
      "test_using_parametrize.py::test_add_three[9-12] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 33%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[-4--1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 40%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 46%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[0-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 53%]\u001b[0m\n",
      "test_using_parametrize.py::test_minus_three[9-12] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 60%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-6] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 66%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-4] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 73%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 80%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[0] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 86%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[3] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 93%]\u001b[0m\n",
      "test_using_parametrize.py::test_reversible_inverse[9] \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m pytest -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e8fee-65ec-4868-bd2c-7c159c412218",
   "metadata": {},
   "source": [
    "## Using pytest.mark.parameterize\n",
    "\n",
    "Allows the same test function to run for many input / output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "429008df-b9dc-4956-9867-5f888b75913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_number(x: int) -> int:\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "633631ef-c0b7-4c89-960e-279cd9cfb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"input_num,expected_output\", [\n",
    "    (2, 4), (-2, 4), (8, 64)\n",
    "])\n",
    "def test_square_number(input_num, expected_output):\n",
    "    ## Arrange\n",
    "    ## Nothing to do here\n",
    "\n",
    "    ## Act\n",
    "    output = square_number(input_num)\n",
    "\n",
    "    ## Assert\n",
    "    assert output == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d964765-2ca7-4e76-bd7f-0af7444fb5d7",
   "metadata": {},
   "source": [
    "## Fixtures\n",
    "\n",
    "Allow re-use of setup objects that you use again and again - for instance reading an input file. Here's an example from pycodif:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c76cdc-e209-45ea-86e6-f2c9df273b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just for an example - this won't run.\n",
    "## The \"example_frame\" code is executed before each test\n",
    "## and the output passed in the \"example_frame\" argument.\n",
    "class TestCODIFFrame:\n",
    "\n",
    "    @pytest.fixture()\n",
    "    def example_frame(self):\n",
    "        with open(\"tests/test_files/test_codif.codif\", \"rb\") as f:\n",
    "            codif = CODIFFrame(f)\n",
    "        return codif\n",
    "\n",
    "    def test_data_parsing(self, example_frame):\n",
    "        assert hasattr(example_frame, \"header\")\n",
    "        assert hasattr(example_frame, \"data_array\")\n",
    "        assert hasattr(example_frame, \"sample_timestamps\")\n",
    "\n",
    "    def test_data_values(self, example_frame):\n",
    "        assert isinstance(example_frame.data_array, np.ndarray)\n",
    "        assert example_frame.data_array.dtype == np.dtype(\"complex64\")\n",
    "        assert example_frame.data_array[0, 0] == -23 + 45j\n",
    "        assert example_frame.data_array[0, -1] == 113 - 89j\n",
    "        assert example_frame.data_array[-1, 0] == 45j\n",
    "        assert example_frame.data_array[-1, -1] == -43 + 58j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02113b5b-8bd9-4590-9465-f62c6ba74dd8",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "This is a package that generates test cases for us based on properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "435210e6-4cf6-4799-8379-ce1a1851c8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hypothesis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Taken from hypothesis quickstart guide:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhypothesis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m given, strategies \u001b[38;5;28;01mas\u001b[39;00m st\n\u001b[32m      4\u001b[39m \u001b[38;5;129m@given\u001b[39m(st.integers(\u001b[32m0\u001b[39m, \u001b[32m200\u001b[39m))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_integers\u001b[39m(n):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m n < \u001b[32m50\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'hypothesis'"
     ]
    }
   ],
   "source": [
    "# Taken from hypothesis quickstart guide:\n",
    "# https://hypothesis.readthedocs.io/en/latest/quickstart.html\n",
    "from hypothesis import given, strategies as st\n",
    "\n",
    "@given(st.integers(0, 200))\n",
    "def test_integers(n):\n",
    "    assert n < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce02f12-0d4b-4b6e-b523-71e4dd59c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "def square(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 2\n",
    "\n",
    "def square_root(x: Union[int, float]) -> Union[int, float]:\n",
    "    return x ** 0.5\n",
    "\n",
    "@given(s=st.integers()):\n",
    "def test_inverses_integers(s):\n",
    "    assert np.isclose(s, square(square_root(s))\n",
    "    assert np.isclose(s, square_root(square(s))\n",
    "\n",
    "@given(s=st.floats()):\n",
    "def test_inverses_floats(s):\n",
    "    assert np.isclose(s, square(square_root(s))\n",
    "    assert np.isclose(s, square_root(square(s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
